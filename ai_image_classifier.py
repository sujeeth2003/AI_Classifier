# -*- coding: utf-8 -*-
"""AI image Classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rFznzJBoNGevvMh9CaddxzQrxiKeY8xL
"""

!pip install -U diffusers transformers accelerate safetensors torch

import os
import torch
from diffusers import DiffusionPipeline
from tqdm import tqdm

device = "cuda" if torch.cuda.is_available() else "cpu"

PROMPTS = [
    "A realistic portrait photo of a man, studio lighting",
    "A futuristic city at night, cyberpunk style",
    "A cat wearing a space suit, cinematic lighting",
    "An oil painting of a medieval knight",
    "A DSLR photo of a mountain landscape at sunrise"
]

MODELS = {
    "sd15": "rupeshs/LCM-runwayml-stable-diffusion-v1-5",
    "sdxl": "stabilityai/sdxl-turbo",
    "pixart": "PixArt-alpha/PixArt-Sigma-XL-2-1024-MS",
}

def load_pipeline(model_id):
    pipe = DiffusionPipeline.from_pretrained(
        model_id,
        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32
    )
    pipe.to(device)
    pipe.set_progress_bar_config(disable=True)
    return pipe

BASE_DIR = "/content/dataset"
os.makedirs(BASE_DIR, exist_ok=True)

IMAGES_PER_PROMPT = 3

for label, model_id in MODELS.items():
    print(f"\nGenerating images for {label}")

    out_dir = os.path.join(BASE_DIR, label)
    os.makedirs(out_dir, exist_ok=True)

    pipe = load_pipeline(model_id)

    idx = 0
    for prompt in tqdm(PROMPTS):
        for _ in range(IMAGES_PER_PROMPT):
            image = pipe(
                prompt,
                num_inference_steps=4,
                guidance_scale=1.0
            ).images[0]

            image.save(f"{out_dir}/{label}_{idx:04d}.png")
            idx += 1

    del pipe
    torch.cuda.empty_cache()

!zip -r dataset.zip /content/dataset

from google.colab import files
files.download("dataset.zip")

!pip install -q opencv-python scikit-image pandas scikit-learn

import os
import cv2
import numpy as np
import pandas as pd

from skimage.color import rgb2hsv
from skimage.measure import shannon_entropy
from tqdm import tqdm

BASE_DIR = "/content/dataset"

labels = sorted(os.listdir(BASE_DIR))
label_map = {name: idx for idx, name in enumerate(labels)}

print(label_map)

def extract_features(img_path):
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = img.astype(np.float32) / 255.0

    h, w, _ = img.shape
    pixels = h * w

    # ---- Color stats ----
    r, g, b = img[:,:,0], img[:,:,1], img[:,:,2]

    features = {}

    features["r_mean"] = np.mean(r)
    features["g_mean"] = np.mean(g)
    features["b_mean"] = np.mean(b)

    features["r_std"] = np.std(r)
    features["g_std"] = np.std(g)
    features["b_std"] = np.std(b)

    features["r_pct"] = np.sum(r) / (np.sum(img) + 1e-6)
    features["g_pct"] = np.sum(g) / (np.sum(img) + 1e-6)
    features["b_pct"] = np.sum(b) / (np.sum(img) + 1e-6)

    # ---- HSV ----
    hsv = rgb2hsv(img)
    features["h_mean"] = np.mean(hsv[:,:,0])
    features["s_mean"] = np.mean(hsv[:,:,1])
    features["v_mean"] = np.mean(hsv[:,:,2])

    # ---- Sharpness (Laplacian variance) ----
    gray = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)
    features["sharpness"] = cv2.Laplacian(gray, cv2.CV_64F).var()

    # ---- Edge strength (Sobel) ----
    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0)
    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1)
    features["edge_strength"] = np.mean(np.sqrt(sobelx**2 + sobely**2))

    # ---- Frequency domain ----
    fft = np.fft.fft2(gray)
    fft_shift = np.fft.fftshift(fft)
    features["fft_energy"] = np.mean(np.abs(fft_shift))

    # ---- Texture ----
    features["entropy"] = shannon_entropy(gray)
    features["contrast"] = np.std(gray)
    features["brightness"] = np.mean(gray)

    return features

rows = []

for label_name, label_id in label_map.items():
    folder = os.path.join(BASE_DIR, label_name)

    for img_file in tqdm(os.listdir(folder), desc=f"Processing {label_name}"):
        img_path = os.path.join(folder, img_file)
        feats = extract_features(img_path)
        feats["label"] = label_id
        feats["model"] = label_name
        rows.append(feats)

df = pd.DataFrame(rows)
df

csv_path = "/content/image_features.csv"
df.to_csv(csv_path, index=False)
print("Saved to:", csv_path)

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

X = df.drop(columns=["label", "model"])
y = df["label"]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

clf = RandomForestClassifier(
    n_estimators=300,
    random_state=42
)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(
    y_test,
    y_pred,
    target_names=[label for label in label_map]
))